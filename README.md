# Parking Environment Demo

This repository packages a modular parking environment, ready for interactive demos and steering-assist tuning. The workflow is built around a Conda environment (`parking-rl`) and a Jupyter notebook that orchestrates the individual scripts.

## Environment

- Conda version used: **25.7.0** (from Anaconda/Miniconda).
- Environment definition: [`environment.yml`](environment.yml).

Recreate the environment on a new machine:

```bash
conda env create -f environment.yml
conda activate parking-rl
python -m ipykernel install --user --name parking-rl --display-name "python3 (parking-rl)"
```

If the environment already exists:

```bash
conda env update -f environment.yml --prune
conda activate parking-rl
```

Ensure Qt GUI support is available (the environment installs `pyqt>=5.15`). On headless Linux hosts you may need to export `QT_QPA_PLATFORM=offscreen` or use X11 forwarding. The environment also bundles the classic Jupyter Notebook server so you can launch the demo straight from this Conda env.

Launch Jupyter against this environment: when opening `ParkingEnv_Demo.ipynb`, pick the kernel shown as `python3 (parking-rl)` so the notebook runs inside the freshly created environment.

## Project Layout

```
parking_project/
├── generate_training_config.py   # CLI to synthesize random training configs
├── main.py                       # CLI entry point for manual/random parking runs
├── parking_gym.py                # Gymnasium environment definition and helpers
├── assist_model_tuner.py         # Qt-backed Matplotlib tuner for steering/velocity assists
├── generated_configs/
│   ├── notebook_override.json    # Live-config edited by the notebook/tuner
│   └── train_001.json            # Sample training config generated by CLI
└── ParkingEnv_Demo.ipynb         # Notebook front-end controlling the entire demo

README.md                         # This file
environment.yml                   # Conda environment specification
```

The workflow is modular: JSON configs capture scenario parameters, the notebook drives high-level actions, and standalone scripts handle CLI demos and steering tuning.

### Default Scenario Snapshot

- `dt = 0.1 s`, `max_steps = 4000` per episode.
- Field is a 60 m × 60 m square, spawn region defaults to `[-6, 6]` in both axes.
- Nine lidar rays (angles `[-135, -90, -60, -30, 30, 60, 90, 135, 0]` degrees) extend to 12 m and contribute to the observation vector.
- Vehicle assist tuning defaults: steering limits ±60° at ±30°/s, steering assist gains `Kp=52.5`, `Kd=8.75`, deadband 0.03 rad/s², longitudinal damping gain 2.45 with 0.03 m/s deadband, assist enabled by default.
- Observation noise is enabled with σ=0.005; call `env.unwrapped.set_observation_noise(enabled=False)` for evaluation runs.

`parking_gym.DEFAULT_CONFIG` is the single source of truth for these values; the notebook’s `generated_configs/notebook_override.json` mirrors the same defaults but is safe to edit interactively.

## Usage

### 1. Launch the Notebook

Within the activated environment:

```bash
cd parking_project
jupyter notebook ParkingEnv_Demo.ipynb
```

The notebook guides you through:

1. Setting run parameters (episodes, max steps, mode).
2. Choosing or editing configuration JSON files.
3. Launching the assist-model tuner (`assist_model_tuner.py`) with Qt sliders for steering/velocity assists.
4. Starting the CLI parking demo (`main.py`) in manual or random mode.
5. Inspecting environment usage tips (state/action layout, observation noise switches) in the final Markdown cell.

All key actions (writing configs, spawning CLI commands) are exposed as notebook cells; no direct script editing is required for normal usage.

### 2. Assist-Model Tuning (Command Line)

You can also launch the tuner from a terminal:

```bash
conda run -n parking-rl python assist_model_tuner.py \
  --config generated_configs/notebook_override.json \
  --angle0 20 --rate0 0 --steps 200 --sync
```

Sliders adjust the steering return and velocity damping assists; when `--sync` is supplied, each adjustment writes back to the JSON file.

### 3. CLI Parking Demo

Run manual or random episodes without the notebook:

```bash
conda run -n parking-rl python main.py \
  --mode manual --episodes 1 --max-steps 4000 \
  --config generated_configs/notebook_override.json
```

Optional flags:

- `--mode random` for scripted random-agent control.
- `--sleep-scale <float>` to slow down or speed up animation.

### 4. Training Config Generator

Produce a fresh randomized config (scene geometry only—timing, vehicle limits, and lidar layout remain at the tuned defaults):

```bash
conda run -n parking-rl python generate_training_config.py \
  --out generated_configs/train_001.json
```

## Notes for Contributors

- The repo targets Python 3.8 for compatibility with Gymnasium 0.29.
- GUI windows rely on Matplotlib’s `QtAgg` backend.
- JSON configs embed bilingual notes; the assist-model tuner preserves UTF-8 characters on write.
- `generate_training_config.py` deep-copies `DEFAULT_CONFIG` and only randomizes spawn/slot/obstacle fields so controller-related tuning stays centralized.
- If you adjust parameters outside the notebook, ensure `--sync` is enabled when tuning to keep the JSON file up to date.

Happy parking!